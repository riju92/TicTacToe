{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "dataset = np.loadtxt('./tictac_multi.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[:, : 9 ]\n",
    "Y = dataset[:, 9 : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6551, 9)\n",
      "(6551, 9)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from numpy import arange\n",
    "from numpy import argmax\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import metrics\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply threshold to positive probabilities to create labels\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def MLP(train_X, test_X, train_Y, test_Y):\n",
    "    n_neighbors = 15\n",
    "    print(test_X.shape)\n",
    "    print(test_Y.shape)\n",
    "    parameter_space = {\n",
    "    'hidden_layer_sizes': [(100,50,25,9)],\n",
    "    'activation': ['tanh', 'relu', 'sigmoid'],\n",
    "    'solver': ['adam','lbfgs','sgd'],\n",
    "    'alpha': [0.0001, 0.05],\n",
    "    'learning_rate': ['constant','adaptive','invscaling'],\n",
    "    }\n",
    "    mlp = MLPRegressor(random_state=1, max_iter=1000)\n",
    "    clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
    "    clf.fit(train_X, train_Y)\n",
    "    res = clf.predict(test_X)\n",
    "    res_cm = res\n",
    "    \n",
    "    # Best paramete set\n",
    "    print('Best parameters found:\\n', clf.best_params_)\n",
    "\n",
    "    # All results\n",
    "    means = clf.cv_results_['mean_test_score']\n",
    "    stds = clf.cv_results_['std_test_score']\n",
    "    #print(\"#### HYPER PARAMETERS ########\")\n",
    "    #for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "        #print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
    "        \n",
    "    # define thresholds\n",
    "    thresholds = arange(0, 1, 0.001)\n",
    "    \n",
    "    # evaluate each threshold\n",
    "    scores = [f1_score(test_Y, to_labels(res, t), average = 'weighted') for t in thresholds]\n",
    "    # get best threshold\n",
    "    ix = argmax(scores)\n",
    "    print('Threshold=%.3f, F-Score=%.5f' % (thresholds[ix], scores[ix]))\n",
    "    threshold_res = np.where(res < thresholds[ix], 0, 1)\n",
    "    print(\"########## Y_actual #########\")\n",
    "    print(test_Y)\n",
    "    print(\"######### T_RES ############\")\n",
    "    print(threshold_res)\n",
    "#     res = np.asarray(res)\n",
    "#     res = np.reshape(res, (-1, test_Y.shape[0]))\n",
    "#     accuracy = 0.0\n",
    "#     for i in range(res.shape[1]):\n",
    "#         if(res[0][i] == test_Y[i][0]):\n",
    "#             accuracy += 1\n",
    "    \n",
    "    #print(accuracy)\n",
    "    #print(\"Accuracy = \" + str(accuracy/res.shape[1]))\n",
    "    accuracy = 0\n",
    "    print('Mean Absolute Error:', metrics.mean_absolute_error(test_Y, threshold_res))\n",
    "    print('Mean Squared Error:', metrics.mean_squared_error(test_Y, threshold_res))\n",
    "    mse = np.sqrt(metrics.mean_squared_error(test_Y, threshold_res))\n",
    "    print('Root Mean Squared Error:', mse)\n",
    "    \n",
    "    accuracy = 100 - (mse * 100)\n",
    "    print(\"Accuracy:\" + str(accuracy))\n",
    "    \n",
    "    print(\"#### CONFUSION MATRIX ##########\")\n",
    "    rounded_labels = np.argmax(test_Y, axis = 1)\n",
    "    cm = confusion_matrix(rounded_labels, res_cm.argmax(axis = 1))\n",
    "    cm = cm / cm.sum(axis=1)[:, np.newaxis]\n",
    "    print(cm)\n",
    "    return accuracy, threshold_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(665, 9)\n",
      "(665, 9)\n"
     ]
    }
   ],
   "source": [
    "from skmultilearn.model_selection import IterativeStratification\n",
    "\n",
    "accuracy_max = 0.0\n",
    "accuracy_min = 100.0\n",
    "accuracy_avg = 0.0\n",
    "\n",
    "best_clf = 0\n",
    "\n",
    "k_cross_fold = 10\n",
    "\n",
    "skf = IterativeStratification(n_splits = k_cross_fold)\n",
    "for train_index, test_index in skf.split(X, Y):\n",
    "    train_X, test_X = X[train_index], X[test_index]\n",
    "    train_Y, test_Y = Y[train_index], Y[test_index]\n",
    "    \n",
    "    accuracy, clf = MLP(train_X, test_X, train_Y, test_Y)\n",
    "    #accuracy *= 100\n",
    "    \n",
    "    if(accuracy > accuracy_max):\n",
    "        accuracy_max = accuracy\n",
    "        best_clf = clf\n",
    "    accuracy_min = min(accuracy_min, accuracy)\n",
    "    accuracy_avg += accuracy\n",
    "    \n",
    "    print(\"#######################\")\n",
    "    \n",
    "print(\"Max accuracy = \" + str(accuracy_max))\n",
    "print(\"Min accuracy = \" + str(accuracy_min))\n",
    "print(\"Avg accuracy = \" + str(accuracy_avg/k_cross_fold))\n",
    "filename = 'mlp_model.pkl'\n",
    "pickle.dump(clf, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
